{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 입력층 개수, 은닉층 깊이, 은닉층 개수, 출력층 개수를 입력 받아\n",
    "# 가중치의 개수(유전자 길이)를 리턴해주는 함수\n",
    "def WeightCount(input_count, hidden_depth, hidden_count, output_count):\n",
    "    count = input_count * hidden_count          # 입력층과 은닉층 사이의 가중치 개수\n",
    "    for _ in range(hidden_depth):               # 은닉층과 은닉층 사이의 가중치 개수\n",
    "        count += hidden_count * hidden_count    \n",
    "    count += hidden_count * output_count        # 은닉층과 출력층 사이의 가중치 개수 \n",
    "    return count\n",
    "\n",
    "# 모집단 생성 함수\n",
    "def MakePopulation(population_size, length):\n",
    "    chromosomes = []\n",
    "\n",
    "    # population size 만큼 반복\n",
    "    for i in range(population_size):\n",
    "\n",
    "        # -1과 1사이의 랜덤 실수로 가중치 구성 \n",
    "        chromosome = [round(random.uniform(-1, 1), 5) for _ in range(length)]\n",
    "        chromosomes.append(chromosome)\n",
    "    return chromosomes\n",
    "\n",
    "\n",
    "\n",
    "# 전방향 계산 수행하는 함수\n",
    "def Forward(input, chromosome, hidden_depth, hidden_count, output_count, length):\n",
    "    inputs = input\n",
    "    bias = 1\n",
    "    sum = [] # 은닉층의 활성화 값 저장 \n",
    "\n",
    "    # 입력층과 첫 번째 은닉층 사이의 가중치 계산\n",
    "    for i in range(0, hidden_count):\n",
    "        weighted_sum = bias\n",
    "        # 활성화 값 계산\n",
    "        for k in range(len(inputs)):\n",
    "            weighted_sum += inputs[k] * chromosome[len(inputs) * i + k]\n",
    "        sum.append(weighted_sum)\n",
    "\n",
    "    # 추가 은닉층과 출력층 사이의 가중치 계산\n",
    "    for i in range(hidden_depth - 1):\n",
    "        new_sum = []\n",
    "        weight_start = len(inputs) * hidden_count + i * (hidden_count ** 2) # 사용할 chromosome의 시작 인덱스 계산 \n",
    "        # 활성화 값 계산 \n",
    "        for j in range(0, hidden_count):\n",
    "            weighted_sum = bias\n",
    "            for k in range(0, len(sum)):\n",
    "                weighted_sum += sum[k] * chromosome[weight_start+ len(sum) * j + k]\n",
    "            new_sum.append(weighted_sum)\n",
    "        sum = new_sum\n",
    "\n",
    "    # 출력층의 가중합 계산 (출력 값이 1개 일 때)\n",
    "    weighted_sum = bias\n",
    "    new_sum = []\n",
    "    ouput_weight = length - hidden_count * output_count # 사용할 chromosome의 시작 인덱스 계산 \n",
    "\n",
    "    for j in range(0, len(sum)):\n",
    "        weighted_sum += sum[j] * chromosome[ouput_weight + j]\n",
    "\n",
    "    return round(weighted_sum, 5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 불러오기 및 전처리\n",
    "data = load_breast_cancer() # 라이브러리 \n",
    "X, y = data.data, data.target #  X는 입력 데이터 (특성), y는 입력에 대한 이진 분류 목표 레이블\n",
    "X = StandardScaler().fit_transform(X) # 데이터 표준화, 평균을 0, 표준 편자를 1\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "# k-Fold 교차 검증을 위한 k 값 설정\n",
    "k = 3  # 예시로 k=3을 사용\n",
    "\n",
    "# KFold 객체 생성\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# 폴드별 정확도를 저장할 리스트\n",
    "fold_accuracies = []\n",
    "\n",
    "# 폴드별 Fitness 값을 저장할 리스트\n",
    "fold_fitness = []\n",
    "\n",
    "# 모든 폴드에 대해 반복\n",
    "all_train_fitness_history = []  # 모든 폴드의 Fitness 값을 저장할 리스트 추가\n",
    "all_fold_accuracy_history = []  # 모든 폴드의 정확도를 저장할 리스트 추가\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "\n",
    "    # 폴드 별 훈련 데이터와 테스트 데이터를 나눔 \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # 에러율 기록\n",
    "    train_fitness_history = []\n",
    "    best_chromosome_history = []\n",
    "    accuracy_history = []\n",
    "\n",
    "    # 입력층 개수를 입력 데이터의 특성 개수로 설정\n",
    "    input_count = X_train.shape[1]\n",
    "    hidden_depth = 1  # 은닉층 깊이를 5로 설정\n",
    "    hidden_count = 5  # 은닉층 개수를 3으로 설정\n",
    "    output_count = 1  # 출력층은 이진 분류 문제이기 때문에 1로 설정 \n",
    "\n",
    "    # NN의 구조를 입력하여 총 가중치의 개수 리턴\n",
    "    length = WeightCount(input_count, hidden_depth, hidden_count, output_count)\n",
    "\n",
    "    # 총 가중치의 개수와 모집단 내 개체수를 매개변수로 주어 모집단 리턴\n",
    "    population_size = 20  # 모집단 크기 증가\n",
    "    chromosomes = MakePopulation(population_size, length)\n",
    "\n",
    "    # GA 학습 시작\n",
    "    iteration_count = 500  # 학습 세대를 500으로 정의\n",
    "\n",
    "    # best_chromosome = None\n",
    "\n",
    "    # GA 반복 \n",
    "    for G in range(iteration_count):\n",
    "\n",
    "        train_fit = []\n",
    "        \n",
    "        for i, chromosome in enumerate(chromosomes):\n",
    "            train_predictions = []\n",
    "\n",
    "            mse_err = 0.0\n",
    "            # 각 chromosome 별, train 데이터 입력 \n",
    "            for x in X_train:\n",
    "                train_predictions.append(Forward(x, chromosome, hidden_depth, hidden_count, output_count, length))\n",
    "\n",
    "            # MSE 손실함수 계산 (하나의 chromosome 별 입력값에 대한 평균 제곱 오차)\n",
    "            mse_err = round(np.mean((y_train - train_predictions) ** 2), 5)\n",
    "            train_fit.append(mse_err)\n",
    "\n",
    "        # train_fit를 정렬하고 train_fitness 보존\n",
    "        train_fitness = train_fit\n",
    "\n",
    "        # 제일 낮은 fitness 을 히스토리 배열에 삽입\n",
    "        best_fit = min(train_fitness)\n",
    "        train_fitness_history.append(best_fit)\n",
    "\n",
    "        # 각 세대 별 베스트 크로모종 출력 및 베스트 크로모종 히스토리 배열에 삽입\n",
    "        best_chromosome = chromosomes[train_fitness.index(min(train_fitness))]\n",
    "        best_chromosome_history.append(best_chromosome)\n",
    "\n",
    "        # 토너먼트 셀렉션\n",
    "        select_count = 4\n",
    "        if select_count % 2 != 0:\n",
    "            select_count -= 1\n",
    "\n",
    "        parents = []\n",
    "        random_index = random.sample(list(range(population_size)), select_count * 2)\n",
    "        t = 0.5\n",
    "\n",
    "        for j in range(0, len(random_index), 2):\n",
    "            f = random.random()\n",
    "            p1 = random_index[j]\n",
    "            p2 = random_index[j+1]\n",
    "            min_train_fit = min(train_fitness[p1], train_fitness[p2])\n",
    "            max_train_fit = max(train_fitness[p1], train_fitness[p2])\n",
    "            if t >= f:\n",
    "                res = train_fitness.index(min_train_fit)\n",
    "                parents.append(chromosomes[res])\n",
    "            else:\n",
    "                res = train_fitness.index(max_train_fit)\n",
    "                parents.append(chromosomes[res])\n",
    "\n",
    "        # Box crossover\n",
    "        childs = []\n",
    "        random.shuffle(parents)\n",
    "\n",
    "        for i in range(0, len(parents), 2):\n",
    "            child = []\n",
    "            for j in range(0, length):\n",
    "                crossover_res = round(random.uniform(parents[i][j], parents[i+1][j]), 5)\n",
    "                child.append(crossover_res)\n",
    "            childs.append(child)\n",
    "\n",
    "        # # Extended Box crossover\n",
    "        # childs = []\n",
    "        # random.shuffle(parents)\n",
    "        # alpha = 0.1  # 확장률\n",
    "\n",
    "        # for i in range(0, len(parents), 2):\n",
    "        #     child = []\n",
    "        #     for j in range(0, length):\n",
    "        #         m = min(parents[i][j], parents[i+1][j])\n",
    "        #         M = max(parents[i][j], parents[i+1][j])\n",
    "        #         em = m - alpha * (M - m)\n",
    "        #         eM = M + alpha * (M - m)\n",
    "        #         crossover_res = round(random.uniform(em, eM), 5)\n",
    "        #         child.append(crossover_res)\n",
    "        #     childs.append(child)\n",
    "\n",
    "        # Uniform mutation\n",
    "        mutation_rate = 0.1\n",
    "\n",
    "        for i in range(len(childs)):\n",
    "            for j in range(length):\n",
    "                if random.random() < mutation_rate:\n",
    "                    min_val = -1.0\n",
    "                    max_val = 1.0\n",
    "                    mutation_val = round(random.uniform(min_val, max_val), 5)\n",
    "                    childs[i][j] = mutation_val\n",
    "\n",
    "        # GENITOR style Replacement\n",
    "        sort = sorted(train_fit, reverse=True)\n",
    "        for i in range(len(childs)):\n",
    "            n = train_fitness.index(sort[i])\n",
    "            n_c = childs[i]\n",
    "            chromosomes[n] = n_c\n",
    "\n",
    "        test_predictions = []\n",
    "        test_fit = []\n",
    "\n",
    "        for x in X_test:\n",
    "            prediction = Forward(x, best_chromosome, hidden_depth, hidden_count, output_count, length)\n",
    "\n",
    "            # 시그모이드 함수의 출력값을 기준으로 0 또는 1로 변환\n",
    "            binary_prediction = 1 if prediction >= 0.5 else 0\n",
    "\n",
    "            test_predictions.append(binary_prediction)\n",
    "\n",
    "\n",
    "        # MSE 손실함수 계산 (하나의 chromosome 별 입력값에 대한 평균 제곱 오차)\n",
    "        mse_fit = round(np.mean((y_test - test_predictions) ** 2), 5)\n",
    "        test_fit.append(mse_fit)\n",
    "\n",
    "        # 정확도 계산\n",
    "        accuracy = np.sum(np.array(test_predictions) == y_test) / len(y_test)\n",
    "        accuracy_history.append(accuracy)\n",
    "\n",
    "    # 폴드별 정확도 및 손실율 저장\n",
    "    fold_accuracies.append(accuracy)\n",
    "    best_train_fitness_values = min(train_fitness_history)\n",
    "    fold_fitness.append(best_train_error_values)\n",
    "    print(\"\\nFold {}: Accuracy: {}, best_train_fitness_values: {}\".format(fold+1, accuracy, best_train_fitness_values))\n",
    "\n",
    "    # 정확도를 모든 폴드에 대해 기록\n",
    "    all_fold_accuracy_history.append(accuracy_history)\n",
    "\n",
    "    # 손실율을 모든 폴드에 대해 기록\n",
    "    all_train_fitness_history.append(train_fitness_history)\n",
    "\n",
    "# 모든 폴드의 정확도와 손실율 출력\n",
    "print(\"\\nFold Accuracies:\", fold_accuracies)\n",
    "print(\"Fold Errors: \", fold_fitness)\n",
    "\n",
    "# 정확도 평균 계산\n",
    "accuracy_average = np.mean(fold_accuracies)\n",
    "print(\"\\nAccuracy Average:\", accuracy_average)\n",
    "\n",
    "# 정확도 분산 계산\n",
    "accuracy_variance = np.var(fold_accuracies)\n",
    "print(\"Accuracy Variance: \", accuracy_variance) \n",
    "\n",
    "# Fitness 평균 계산\n",
    "fitness_average = np.mean(fold_fitness)\n",
    "print(\"\\nFitness Average:\", fitness_average)\n",
    "\n",
    "# Fitness 분산 계산\n",
    "fitness_variance = np.var(fold_fitness)\n",
    "print(\"fitness Variance: \", fitness_variance) \n",
    "\n",
    "# 그래프 그리기\n",
    "x = range(iteration_count)\n",
    "\n",
    "# 각 폴드의 정확도를 그래프로 표시 (평균은 dashed)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "for fold in range(k):\n",
    "    plt.plot(x, all_fold_accuracy_history[fold], label=f'Fold {fold+1}')\n",
    "\n",
    "# 평균 정확도 표시\n",
    "plt.axhline(y=accuracy_average, color='r', linestyle='--', label='Accuracy Mean')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Over Generations for Each Fold')\n",
    "plt.legend()\n",
    "\n",
    "# 각 폴드의 Fitness 그래프로 표시 (평균은 dashed)\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "for fold in range(k):\n",
    "    plt.plot(x, all_train_fitness_history[fold], label=f'Fold {fold+1}')\n",
    "\n",
    "# 평균 Fitness 표시\n",
    "plt.axhline(y=fitness_average, color='g', linestyle='--', label='Fitness Mean')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('Training Fitness Over Generations for Each Fold')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 각 폴드의 정확도를 막대그래프로 표시\n",
    "plt.bar(range(1, k+1), fold_accuracies)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Each Fold')\n",
    "plt.show()\n",
    "\n",
    "# 각 폴드의 Fitness을 막대그래프로 표시\n",
    "plt.bar(range(1, k+1), fold_fitness)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Fitness')\n",
    "plt.title('Fitness for Each Fold')\n",
    "plt.show()\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "\n",
    "# ax1.set_xlabel('Generation')\n",
    "# ax1.set_ylabel('Error Rate', color='tab:blue')\n",
    "# ax1.plot(x, train_error_history, label=\"Training Error\", color='tab:blue')\n",
    "# ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.set_ylabel('Accuracy', color='tab:red')\n",
    "# ax2.plot(x, accuracy_history, label=\"Accuracy\", color='tab:red')\n",
    "# ax2.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "# fig.tight_layout()\n",
    "# plt.title('Training Error and Accuracy Over Generations')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
